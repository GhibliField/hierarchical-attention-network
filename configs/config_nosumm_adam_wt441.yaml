prefix: han
verbose: True
mode: 'train'
save_dir: 'scratch/checkpoints/nosumm_adam_wt441'
use_gpu: True
debug: False
seed: 23443521
data:
    preprocess: False
    dir: 'scratch'
    review_vocab: 'review_vocab.pkl'
    summary_vocab: 'summary_vocab.pkl'
    train:
        jsonfile: 'audio_train.json.preprocessed'
        batch_size: 32
    val:
        jsonfile: 'audio_dev.json.preprocessed'
        batch_size: 32
    fixed_weights: True
model:
    params:
        word_emb_dim: 200
        gru_hidden_dim: 50
        emb_dim: 100
        use_summary: False
    reload: 'checkpoint.pth.tar'

optim:
    class: adam      #sgd/rmsprop/adam
    params: 
        lr: 0.001      # learning rate
        # alpha: 0.99     # alpha for adagrad/rmsprop/momentum/adam
        # beta: 0.995     # beta used for adam
        # eps: 0.00001       # epsilon that goes into denominator in rmsprop
        weight_decay: 0.0005
training:
    n_epochs: 5
    start_from_checkpoint: True

prefix: han
verbose: True
mode: 'train'
save_dir: 'scratch/checkpoints/summ_adam_wt441_comb_larger'
use_gpu: True
debug: False
seed: 23443521
data:
    dir: 'scratch'
    review_vocab: 'comb_vocab_pruned.pkl'
    summary_vocab: 'comb_vocab_pruned.pkl'
    train:
        jsonfile: 'audio_train.json.preprocessed'
        batch_size: 32
    val:
        jsonfile: 'audio_dev.json.preprocessed'
        batch_size: 32
    weights: [4.0, 4.0, 1.0]
model:
    params:
        word_emb_dim: 200
        rnn_hidden_dim: 100
        emb_dim: 200
        use_summary: True
        combined_lookup: True
        rnn: 'gru'
    reload: 'checkpoint.pth.tar'
optim:
    class: adam      #sgd/rmsprop/adam
    params: 
        lr: 0.001      # learning rate
        # alpha: 0.99     # alpha for adagrad/rmsprop/momentum/adam
        # beta: 0.995     # beta used for adam
        # eps: 0.00001       # epsilon that goes into denominator in rmsprop
        weight_decay: 0.0005
    scheduler:
        factor: 0.4
        patience: 3
training:
    n_epochs: 5
    start_from_checkpoint: True
